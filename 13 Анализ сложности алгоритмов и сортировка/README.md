# Алгоритмы и их сравнения

## Определение “алгоритм”
* Последовательность действий, для решения некоторой задачи Пример: вычисление площади (треугольника, квадрата)
* Для чего нам может понадобиться сравнивать алгоритмы между собой?
Наводящий пример: обмен значений переменных

## Сравнение алгоритмов

```C#
int a= 5;
int b = 7;
int temp;

temp = b
b = a;
a = temp;
```

```C#
int a= 5;
int b = 7;

a = a + b;
b = a - b;
a = a - b;
```

Второй быстрее, так как работает ссылками и не создаёт новую переменную

<br>По каким критериям мы можем сравнить алгоритмы?
* Память
* Время выполнения (скорость)

<br> Сравнение алгоритмов - способы:
* Аналитический
* Экспериментальный

## Big O
Сложность алгоритма - это количественная характеристика, которая говорит о том, сколько времени\памяти потребуется для выполнения алгоритма.
Big O показывает, как сложность алгоритма растёт с увеличением входных данных. Она всегда показывает худший вариант развития событий - верхнюю границу.
Зачем изучать Big O:
* Чтобы уметь видеть и исправлять неоптимальный код.
* Спрашивают на собеседованиях.
* Потеря производительности от непонимания Big O.

Попробуем разобраться…


## Сложность О(1) - константная 
Допустим, у нас есть массив:
```C# 
var array = new int[] {1, 2, 3, 4, 5};
```
Какова сложность доступа к элементу?
```c#
array[0]
array[1]
array[2]
```

Для доступа к элементу массива время, затраченное на его получение - константа.
Сложность О(1) означает, что время, затрачиваемое на выполнение не зависит от входных данных.

Массив в памяти располагается лийно друг за другом, поэтому время у него линейно

## Сложность O(n) - линейная
```C#
var array = new int[] {7, 18, 158, 16, 23};
public void FindElement(int[] array, int element)
{
    for(int i = 0; i < array.Length; i++)
    {
        if(array[i] == element)
        // do something
    }
}

```
Сколько элементов надо перебрать, чтобы найти нужный?


Сложность алгоритма увеличивается линейно с увеличением входных данных.
FindElement на массиве из 10 элементов отработает за Х микросекунд.
А на массиве из 100..10 000 элементов уже за Х*10 … Х*100 микросекунд

## Сложность O(n^2) - квадратичная

```C#
var array = new int[] {7, 18, 158, 16, 23};
public void FindElement(int[] array, int element)
{
    for(int i = 0; i < array.Length; i++)
    {
        for(int j = 0; j < array.Length; j++)
        {
        if(array[i] == array[j] && i != j)
        // do something
        }
    }
}
```

Удвоение размера входных данных увеличивает время выполнения в 4 раза.
Например, при увеличении данных в 10 раз, количество операций (и время выполнения) увеличится примерно в 100 раз.
Если алгоритм имеет квадратичную сложность, то это повод пересмотреть необходимость использования данного алгоритма. Но иногда этого не избежать.

## Сложность O(log n) - логарифмическая
```C#
var array = new int[] {7, 16, 18, 23, 158};
public void FindElement(int[] array, int element)
{
    int median = array.Length / 2;
    int startIndex = 0;
    if (array[median] > element)
    {
        startIndex = median;
    }
    for(int i = 0; i < array.Length; i++)
    {
        if(array[i] == element)
        // do something
    }
}
```

Сложность алгоритма растёт логарифмически с увеличением входных данных.
Другими словами это такой алгоритм, где на каждой итерации берётся половина элементов. 

O(n) * O(log n)
Удвоение размера входных данных увеличит время выполнения чуть более, чем вдвое.
<br>Можно ли улучшить пример с поиском повторяющихся значений с O(n^2) до O(n * log n) ?

![Image alt](https://github.com/IlyaGall/C-/blob/main/11%20%D0%A1%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D0%B8%20%D0%BF%D0%B5%D1%80%D0%B5%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F/img/1.PNG)
